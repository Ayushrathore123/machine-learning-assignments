{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef7f3182",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e698a",
   "metadata": {},
   "source": [
    "Min-Max scaling, also known as normalization, is a data preprocessing technique used to scale the features of a dataset to a specific range. The purpose of Min-Max scaling is to transform the data so that it falls within a predefined range, typically between 0 and 1.\n",
    "\n",
    "The formula to perform Min-Max scaling on a feature is as follows:\n",
    "\n",
    "scaled_value = (value - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa09ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for example \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c4b12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame([20, 30, 40, 50, 60],columns=[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8db08d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff271ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  ],\n",
       "       [0.25],\n",
       "       [0.5 ],\n",
       "       [0.75],\n",
       "       [1.  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max.fit_transform(df[[\"age\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a604b",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee192839",
   "metadata": {},
   "source": [
    "The Unit Vector technique, also known as vector normalization, is a feature scaling method used to transform feature vectors into unit vectors. It scales the features in such a way that each vector has a length of 1, while maintaining the direction of the original vector. Unit Vector scaling is commonly used in machine learning algorithms that rely on distance calculations, such as k-nearest neighbors (KNN) and support vector machines (SVM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffdc1f3",
   "metadata": {},
   "source": [
    "The formula to calculate the unit vector of a feature vector is as follows:\n",
    "\n",
    "unit_vector = vector / ||vector||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb54f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data={\"x\":[2, 4, 6, 8],\"y\":[1, 3, 5, 7]}\n",
    "df1=pd.DataFrame(data,columns=[\"x\",\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16aa5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ac40ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.894427</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768221</td>\n",
       "      <td>0.640184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.658505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.894427  0.447214\n",
       "1  0.800000  0.600000\n",
       "2  0.768221  0.640184\n",
       "3  0.752577  0.658505"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(normalize(df1[[\"x\",\"y\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a41ea",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3799d3f",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a widely used technique in data analysis and machine learning for dimensionality reduction. It transforms a dataset containing a high number of variables into a new set of variables called principal components. These components are linear combinations of the original variables and capture the maximum amount of variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ef4b4",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c182a2",
   "metadata": {},
   "source": [
    "PCA can be used as a feature extraction technique where it identifies the most important features (principal components) that explain the variance in the data. By selecting a subset of these components, PCA effectively reduces the dimensionality of the dataset while preserving the most relevant information. The extracted components can then be used as new features in subsequent analysis or modeling tasks. For example, in facial recognition, PCA can be used to extract facial features such as eyes, nose, and mouth from images, representing them as principal components for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77eac5",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d716e",
   "metadata": {},
   "source": [
    "Price: If the price feature has a wide range of values, Min-Max scaling can be applied to normalize the values between 0 and 1. This ensures that the price values are on a similar scale and prevents one feature from dominating the recommendation process.\n",
    "\n",
    "Rating: The rating feature may have a range of values such as 1 to 5 or 0 to 10. Min-Max scaling can be used to normalize these values between 0 and 1, allowing a fair comparison between different restaurants based on their ratings.\n",
    "\n",
    "Delivery time: The delivery time feature might have varying ranges, such as 10 minutes to 60 minutes or 20 minutes to 120 minutes. Min-Max scaling can be employed to scale these values between 0 and 1, making them comparable and ensuring that delivery time does not disproportionately influence the recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d05f145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_data:\n",
      "   price  raiting  delivery_time\n",
      "0     34        2              8\n",
      "1     43        4              3\n",
      "2     42        2              8\n",
      "3     22        4              7\n",
      "4      5        1              9\n",
      "\n",
      "scaled data:\n",
      "      price   raiting  delivery_time\n",
      "0  0.687500  0.333333       0.888889\n",
      "1  0.875000  1.000000       0.333333\n",
      "2  0.854167  0.333333       0.888889\n",
      "3  0.437500  1.000000       0.777778\n",
      "4  0.083333  0.000000       1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.random.seed(34)\n",
    "data={\n",
    "    \"price\":np.random.randint(1,50,size=100),\n",
    "    \"raiting\":np.random.randint(1,5,size=100),\n",
    "    \"delivery_time\":np.random.randint(10.60,size=100),\n",
    "    \n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "min_max=MinMaxScaler()\n",
    "scaled_data=min_max.fit_transform(df)\n",
    "scaled_data_df=pd.DataFrame(scaled_data,columns=df.columns)\n",
    "\n",
    "print(\"original_data:\")\n",
    "print(df.head())\n",
    "print(\"\\nscaled data:\")\n",
    "print(scaled_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb1989",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company fin\n",
    "ancial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda818b",
   "metadata": {},
   "source": [
    "Normalize the dataset to ensure that all features have the same scale.\n",
    "\n",
    "Compute the covariance matrix of the normalized dataset.\n",
    "\n",
    "Perform eigenvalue decomposition on the covariance matrix to obtain the eigenvectors and eigenvalues.\n",
    "\n",
    "Select the top k eigenvectors based on the corresponding largest eigenvalues.\n",
    "\n",
    "Project the original dataset onto the selected eigenvectors to obtain a reduced-dimensional representation of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c9c56f",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "00a67b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame([1, 5, 10, 15, 20],columns=[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "12770c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x\n",
       "0   1\n",
       "1   5\n",
       "2  10\n",
       "3  15\n",
       "4  20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4971bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1=MinMaxScaler(feature_range=(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77462400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ],\n",
       "       [-0.57894737],\n",
       "       [-0.05263158],\n",
       "       [ 0.47368421],\n",
       "       [ 1.        ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler1.fit_transform(df2[[\"x\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a10b2",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad14d3e3",
   "metadata": {},
   "source": [
    "Calculate the covariance matrix for the dataset, which measures the relationships between the features.\n",
    "\n",
    "Compute the eigenvalues and eigenvectors of the covariance matrix.\n",
    "\n",
    "Analyze the explained variance ratio associated with each principal component. This ratio indicates the amount of variance in \n",
    "the data captured by each component.\n",
    "\n",
    "Determine the number of principal components to retain by selecting a threshold for the cumulative explained variance ratio. You might choose a threshold that captures a significant portion of the total variance, such as 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb35663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15d266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
